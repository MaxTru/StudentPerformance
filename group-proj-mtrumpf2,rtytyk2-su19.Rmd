---
title: 'Prediction of student high school performance considering demographic and social features'
author: "STAT 420: Data Analysis Project - Summer 2019"
date: '2019-08-03 | Maximilian Trumpf (mtrumpf2), Rafal Tytyk (rtytyk2)'
output:
  html_document:
    theme: flatly
    toc: yes
    fig_width: 8
    fig_height: 5
  pdf_document: default
urlcolor: cyan
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE, cache=TRUE}
options(scipen = 1, digits = 2, width = 80, fig.align = "center")
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
library(readr)
library(boot)
library(ggplot2)
library(car)
library(knitr)
library(ggpubr)
```

# Introduction

## Goal and motivation

The main goal of this project is to build a model which is capable of predicting student performance based on demographic and social features. In order to achieve this, we will use a dataset of student performances in secondary education in two Portugese schools (see [Data chapter](#data_chapter) for details and introduction to the dataset).

The dataset contains many predictors, which were collected using a consistent method (surveies and school reports) in a certain context (two defines Portugese schools in 2008). Therefore, the regression model being built will not be well fit for predicting student performance in a different context and with predictors being collected even with a slightly adjusted method. However, the primary goal of the regression model is **to explain the relationship of demographic and social features for student performance**. 

This regression model based explanation is of personal motivation for the authors of this report, since they are both fathers themselves and are interested in learning how to give a supportive environment for their children (although this analysis can of course only cover a very specialized tiny part and should not be understand as an extensive study of how to support children during high school).

## Data {#data_chapter}

### Overview 

This analysis will use the *"Student Performance"* dataset. The dataset documents student performance in secondary education in two Portugese schools. 

The original data provides two datasets covering two distinct subjects: Mathematics (**395 observations**) and Portugese (**649 observations**). Both datasets include the exact same set of attributes (**33 attriutes**, see table below). When merging the two datasets, one will find **382 observations/students** who are present in the data and have taken both courses. (Merged based on ` "school", "sex", "age", "address", "famsize", "Pstatus", "Medu", "Fedu", "Mjob", "Fjob", "reason", "nursery", "internet"`). Since this large overlap would impact the regression significantly (same students in both datasets), the model will primarily be fit on the larger `Portugese` dataset. If promising, we will also model the performance in the `Math` dataset and compare the `Portugese` with the `Math` model in the course of the analysis.

### Attributes

The main attributes to be used are the following:

* Main response: **G1 - first period grade, G2 - second period grade, G3 - final grade** (We will explore which of these is to be used as main response. We also suspect a high multicollinearity, so we will only include one of these and exclude the others as predictors.)
* Main predictors
    * **Sex** (categorial)
    * **Age** (numeric)
    * **Family size** (categorial)\4
    * **Time spend with various activites** (numeric from 1 to 5; see full list of activites below)
    * **Parents' education** (numeric from 1 to 4)
    
The full list of attributes can be found in the following table:

| Id | Name       | Description                                                                                                                                            |
|----|------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|
| 1  | school     | student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)                                                                       |
| 2  | sex        | student's sex (binary: 'F' - female or 'M' - male)                                                                                                     |
| 3  | age        | student's age (numeric: from 15 to 22)                                                                                                                 |
| 4  | address    | student's home address type (binary: 'U' - urban or 'R' - rural)                                                                                       |
| 5  | famsize    | family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)                                                                             |
| 6  | Pstatus    | parent's cohabitation status (binary: 'T' - living together or 'A' - apart)                                                                            |
| 7  | Medu       | mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education) |
| 8  | Fedu       | father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 - 5th to 9th grade, 3 - secondary education or 4 - higher education) |
| 9  | Mjob       | mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')                       |
| 10 | Fjob       | father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')                       |
| 11 | reason     | reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')                                           |
| 12 | guardian   | student's guardian (nominal: 'mother', 'father' or 'other')                                                                                            |
| 13 | traveltime | home to school travel time (numeric: 1 - 1 hour)                                                                                                       |
| 14 | studytime  | weekly study time (numeric: 1 - 10 hours)                                                                                                              |
| 15 | failures   | number of past class failures (numeric: n if 1<=n<3, else 4)                                                                                           |
| 16 | schoolsup  | extra educational support (binary: yes or no)                                                                                                          |
| 17 | famsup     | family educational support (binary: yes or no)                                                                                                         |
| 18 | paid       | extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)                                                                  |
| 19 | activities | extra-curricular activities (binary: yes or no)                                                                                                        |
| 20 | nursery    | attended nursery school (binary: yes or no)                                                                                                            |
| 21 | higher     | wants to take higher education (binary: yes or no)                                                                                                     |
| 22 | internet   | Internet access at home (binary: yes or no)                                                                                                            |
| 23 | romantic   | with a romantic relationship (binary: yes or no)                                                                                                       |
| 24 | famrel     | quality of family relationships (numeric: from 1 - very bad to 5 - excellent)                                                                          |
| 25 | freetime   | free time after school (numeric: from 1 - very low to 5 - very high)                                                                                   |
| 26 | goout      | going out with friends (numeric: from 1 - very low to 5 - very high)                                                                                   |
| 27 | Dalc       | workday alcohol consumption (numeric: from 1 - very low to 5 - very high)                                                                              |
| 28 | Walc       | weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)                                                                              |
| 29 | health     | current health status (numeric: from 1 - very bad to 5 - very good)                                                                                    |
| 30 | absences   | number of school absences (numeric: from 0 to 93)                                                                                                      |
| 31 | G1         | first period grade (numeric: from 0 to 20)                                                                                                             |
| 32 | G2         | second period grade (numeric: from 0 to 20)                                                                                                            |
| 33 | G3         | final grade (numeric: from 0 to 20)                                                                                                                    |
  
### Background information

The data was collected by using school reports and questionnaries. 

The data was accessed on 2019-07-02 via [UCI Machine Learning Repository/Student Performance](http://archive.ics.uci.edu/ml/datasets/Student+Performance#). 

The dataset was collected by Paulo Cortez, University of Minho, Guimarães, Portugal, [http://www3.dsi.uminho.pt/pcortez](http://www3.dsi.uminho.pt/pcortez).

# Methods

## Data preparation

First we will load the data
```{r message=FALSE}
student = read.csv("data/student-por.csv", header = TRUE, sep = ";")
head(student)
```

Check whether we have any missing values
```{r}
any(is.na(student))
```

No missing values, so continue as is.

Validate that the attributes have the desired types
```{r}
str(student)
```

There are two important observations from the structure from the data:

1. Various attributes are clearly categorial predictors (e.g., `romantic (yes, no)`). They were already correctly captured as `factors` during data import, so no further action needed.
2. Some attributes could either be modeled as categorial or as numeric predictors (e.g., `traveltime`, `studytime`).

For now we will:

* Keep the debateable numeric predictors (e.g., `traveltime (1, 2, 3, 4, 5)`) as numeric predictors. Generally this should be okay, since the numbers represent a clear order (they represent `very low` to `very high`). However, it needs to be considered when interpreting the results that the model using these numeric attributes will force the average change of the response between the different values to be the same (e.g., the average change of the response between a student with `traveltime = 1 (very low)` and another student with `traveltime = 2 (low)` will be the same as between a student with `traveltime = 4 (high)` and another student with `traveltime = 5 (very high)`.


## Data overview

### Data exploration

```{r}
summary(student)
```

There are *383 females* and *266 males* in the dataset. A strong majority of *457 to 192 have more than 2 siblings*. Majority of *410 to 239 aren't in romantic relationships* and strong majority of *580 to 69 want higher education*. On average our students report *good health* and *good relationship* with their families. Strong majority of *455 to 194 have mother* as their guardian. Students go out 3 days a week on average, which is as much as they have free time. On average, they are absent from class 3.66 days, with one person being absent 32 days.

```{r}
student[student$absences > 20, c("G1", "G2", "G3", "absences", "sex", "age")]
```

#### Best and worse students

Let's start off by looking at best students, understood as those that scored higher than 17 on `G3`:

```{r}
best_students = student[student$G3 > 17, ]
worst_students = student[student$G3 < 6, ]
```

```{r, echo=FALSE}
roundmean = function(x) round(mean(x), 2)
knitr::kable(
  x = do.call(rbind, list(
    c("Average age", roundmean(best_students$age), roundmean(worst_students$age)),
    c("Average study time", roundmean(best_students$studytime), roundmean(worst_students$studytime)),
    c("How many had a paid tuition", sum(best_students$paid == "yes"), sum(worst_students$paid == "yes")),
    c("Average health", roundmean(best_students$health), roundmean(worst_students$health)),
    c("Average drinking during the week", roundmean(best_students$Dalc), roundmean(worst_students$Dalc)),
    c("Average drinking during the weeekend", roundmean(best_students$Walc), roundmean(worst_students$Walc)),
    c("Average family relationship", roundmean(best_students$famrel), roundmean(worst_students$famrel)),
    c("Average free time", roundmean(best_students$freetime), roundmean(worst_students$freetime))
  )),
  col.names = c("Query", "Best students", "Worst students"),
  digits = c(0, 2, 2),
  format = "markdown")
```

We observe that best students are on average younger, study more and drink less than their worst counterparts, they also tend to have less free time and report worse health. They also didn't do any paid tuition.

#### Guardian

Now we'll look at `G3` performance based on student's primary guardian:

```{r}
boxplot(student$G3 ~ student$guardian, xlab = "guardian", ylab = "G3",
        col = "dodgerblue", main = "Variance of G3 by guardian")
```

We observe that students who's primary guardian is mother have broadest variance on both ends. Fathers tend to limit lower end at the cost of some higher end. Other types of guardians seem to do worse on average, having much smaller variance on both ends.

#### Parents education

Now let's see how parents's education influences their children:

```{r, echo=FALSE}
boxplot(student$G3 ~ student$Medu, xlab = "Mother's education level", ylab = "G3",
        col = "dodgerblue", main = "Variance of G3 by Mother's education level")
```

```{r, echo=FALSE}
boxplot(student$G3 ~ student$Fedu, xlab = "Father's education level", ylab = "G3",
        col = "dodgerblue", main = "Variance of G3 by Father's education level")
```

It can be observed that students who's parents are highly educated do best on average, although there are similar levels of variations across the groups of 1+.

Students having at least one the parents uneducated do not get lower than 10 but also no higher than 13 points, with the exception of 2 students:

```{r}
subset(student, subset = (Fedu == 0 | Medu == 0) & G3 > 13, 
       select = c("G1", "G2", "G3", "age", "sex", "Medu", "Mjob",  "Fedu", "Fjob", "paid", "activities"))
```

#### Health

Let's visualize how healthy are our students:

```{r, echo=FALSE}
hist(student$health, col = "dodgerblue", breaks=5, main = "Histogram of health", xlab = "health")
```

- `r mean(student$health >= 3)*100.0`% students report their health to be 3 and up,
- `r mean(student$health < 3)*100.0`% students report health below 3.

Let's visualize if health influences `G3` in significant way:

```{r, echo=FALSE}
ggplot(data = student, aes(x=health, y=G3, color=sex)) + geom_smooth(aes(group=sex), method="lm", se=FALSE)
```

Strangely, we're observing small, but inverse relationship between `health` and `G3`. Perhaps feeling good take students off their studying.

#### Age

Let's visualize relationship between `age`, `sex` and `G3`:

```{r, echo=FALSE}
ggplot(data = student, aes(x=age, y=G3, color=sex))+geom_smooth(aes(group=sex), method="lm", se=FALSE)
```

We notice inverse relationship between `age` and `G3` performance for both sexes. Females are doing on average better than males by $`r mean(student[student$sex == 'F', 'G3']) - mean(student[student$sex == 'M', 'G3'])`$ points on `G3` and while no females over 21 are present in the dataset, there is 1 male student aged 22, doing the worst - a potential outlier:

```{r}
student[student$age == 22, c("sex", "age", "G1", "G2", "G3", 
                             "higher", "failures", "studytime", "famsize")]
```


#### Studytime, Absences

Now let's observe how `studytime` and `absences` affect `G3`. We'll divide results by `sex`:

```{r, echo=FALSE}
ggarrange(
  ggplot(student, aes(x=absences, y=G3, color=sex))+geom_smooth(aes(group=sex), method="lm", se=FALSE),
  ggplot(student, aes(x=studytime, y=G3, color=sex))+geom_smooth(aes(group=sex), method="lm", se=FALSE)
)
```

We're seeing a positive relationship between `studytime` and `G3` result, greater by a point than the inverse relationship between `absences` and `G3`. We'd expect students that do study in their free time should do better even if they miss the school.

+ Average of G3 based on absences:
  + Having 16 and more absences: `r mean(student[student$absences >= 16, "G3"])`,
  + Having less than 16 absences: `r mean(student[student$absences < 16, "G3"])`,


+ Average of G3 based on study time:
  + Studied 3/5 or more: `r mean(student[student$studytime >= 3, "G3"])`,
  + Studied 2/5 or less: `r mean(student[student$studytime < 3, "G3"])`,


#### Alkohol consumption and Activities

Now we'll look how alkohol consumption affect `G3` performance. We'll group the plots into people who take off-school `acivities` and those who do not.

```{r, echo=FALSE}
ggarrange(
  ggplot(data = student, aes(x=Walc, y=G3, color=activities))
    + geom_smooth(aes(group=activities), method="lm", se=FALSE) + xlab("Weekend Alkohol Consumption"),
  ggplot(data = student, aes(x=Dalc, y=G3, color=activities))
    + geom_smooth(aes(group=activities), method="lm", se=FALSE) + xlab("Daily Alkohol Consumption")
)
```

We can clearly observe that daily consumption of alkohol resolves in much worse performance than weekend consumption. The effect is made even larger by lack of `activities`, especially for people consuming alkohol daily.

Let's look how much are students drinking:

```{r}
par(mfrow=c(1,2))
hist(student$Dalc, col = "dodgerblue", xlab = "Daily drinking", main = "Histogram of daily drinking")
hist(student$Walc, col = "dodgerblue", xlab = "Weekend drinking", main = "Histogram of weekend drinking")
```

Good to know that vast majority of students drink very little or not at all, and the majority of weekend drinkers are also aiming for lowest possible levels of intoxication or at least they report so, although we're seeing a lot more of weekend drinkers.

+ No. of drinkers:
  + Light weekend drinkers: `r sum(student$Walc < 3)`,
  + heavy weekend drinkers: `r sum(student$Walc >= 3)`,
  + light daily drinkers: `r sum(student$Dalc < 3)`,
  + heavy daily drinkers: `r sum(student$Dalc >= 3)`.


### Data correlation

Evaluate correlation
```{r}
# Evaluate correlation
cor_matrix = cor(student[, sapply(student, is.numeric)])
which( cor_matrix > 0.7 & cor_matrix < 1.0, arr.ind = T)
```

There are ``r sum(cor_matrix > 0.7 & cor_matrix < 1.0)`` pairs of numeric attributes with a high correlation of above `0.7`. However, they are `G1`, `G2` and `G3` (as we expected). We will use one of the grades as a response and ignore the others. Therefore we don't expect mutlicollinearity issues.

Visualize distribution of response attribute `G3`
```{r}
hist(student$G3,   
     xlab        = "G3 grade (student performance)",
     main        = "Histogram of G3",
     breaks      = 20,
     xlim        = c(0, 20),
     col         = "dodgerblue",
     border      = "black",
     probability = TRUE)
curve(dnorm(x, mean = mean(student$G3), sd = sd(student$G3)), col = "green", add = TRUE, lwd = 2)
points(dpois(x = 0:20, lambda = 10), col = "orange", pch = 20, cex = 2)
```

From a visual inspection, the response could either follow a normal (green curve) or a Poisson distribution (orange points). Since there is not a large delta of the "fit", we will continue with using **Linear Regression Models** over **Generalized Linear Models with link function for Poisson distribution**.

## Linear and Logistic Regression

We will explore formulating the problem as linear (predict the grade) as well as logistic (predict `pass/fail`) problem.

### Data Split

We'll split our dataset into train/test sets:

```{r}
set.seed(42)
#trn_idx = sample(nrow(student), round(nrow(student)*.8))
# To ensure consistent results across linux and Windows we hard code the randomly generated idx
trn_idx = c(594, 608, 186, 537, 414, 335, 474, 87, 422, 452, 293, 459, 596, 163, 294, 637, 620, 75, 300, 354, 569, 88, 621, 593, 52, 321, 244, 564, 278, 519, 457, 502, 240, 423, 3, 512, 5, 128, 554, 374, 232, 265, 23, 590, 262, 579, 536, 386, 584, 372, 200, 208, 238, 468, 24, 445, 402, 102, 155, 304, 398, 578, 446, 332, 498, 111, 159, 482, 403, 140, 25, 82, 125, 277, 114, 413, 613, 215, 635, 1, 331, 90, 204, 366, 439, 318, 132, 51, 49, 171, 610, 570, 117, 633, 514, 407, 185, 285, 410, 341, 344, 120, 119, 213, 555, 524, 626, 589, 290, 2, 329, 451, 404, 243, 287, 535, 558, 190, 326, 440, 189, 217, 303, 311, 378, 207, 481, 503, 122, 377, 469, 313, 327, 484, 438, 299, 641, 59, 391, 319, 76, 41, 236, 395, 371, 412, 86, 475, 148, 632, 359, 162, 388, 196, 336, 384, 93, 15, 67, 334, 458, 269, 571, 96, 260, 642, 219, 153, 56, 568, 350, 197, 198, 229, 567, 65, 511, 280, 375, 362, 431, 646, 149, 121, 346, 347, 425, 367, 62, 133, 480, 360, 614, 619, 33, 604, 241, 562, 495, 330, 542, 609, 381, 477, 71, 478, 429, 572, 112, 115, 597, 552, 501, 27, 444, 365, 249, 582, 507, 494, 211, 74, 448, 551, 134, 348, 130, 79, 21, 104, 437, 491, 127, 8, 645, 490, 36, 499, 228, 173, 28, 230, 29, 522, 223, 195, 643, 61, 201, 520, 463, 500, 108, 443, 9, 315, 44, 212, 224, 242, 279, 48, 466, 566, 193, 625, 333, 513, 353, 337, 430, 297, 560, 379, 586, 126, 548, 151, 178, 137, 172, 19, 69, 489, 373, 63, 505, 7, 123, 11, 312, 605, 113, 138, 547, 32, 268, 546, 376, 12, 169, 591, 421, 575, 606, 624, 135, 55, 110, 105, 37, 471, 168, 630, 649, 526, 99, 528, 545, 517, 142, 616, 47, 92, 184, 527, 116, 272, 427, 453, 295, 533, 640, 417, 352, 600, 380, 383, 254, 91, 316, 611, 246, 601, 13, 305, 541, 357, 603, 274, 563, 369, 22, 561, 483, 580, 401, 627, 145, 370, 585, 188, 81, 281, 325, 166, 175, 261, 550, 534, 26, 638, 396, 308, 496, 648, 523, 30, 16, 225, 157, 559, 98, 449, 583, 338, 389, 253, 45, 607, 473, 136, 349, 456, 515, 577, 245, 476, 139, 368, 6, 612, 156, 420, 216, 436, 239, 581, 464, 493, 322, 251, 57, 400, 35, 574, 543, 181, 504, 14, 623, 306, 405, 255, 361, 17, 340, 509, 432, 465, 302, 355, 267, 250, 599, 4, 89, 296, 525, 592, 258, 192, 222, 177, 461, 95, 276, 164, 399, 345, 406, 382, 356, 328, 80, 60, 50, 275, 556, 161, 266, 492, 424, 408, 576, 118, 256, 235, 72, 247, 364, 622, 289, 518, 199, 472, 307, 180, 301, 639, 40, 97, 141, 553, 419, 428, 146, 508, 647, 416, 298, 77, 460, 390, 544, 203, 557, 450, 263, 573, 320, 252, 158, 218, 259, 129, 83, 467, 248, 234, 539, 107, 538, 42, 644, 282, 565, 487, 46)
student_trn = student[trn_idx, ]
student_tst = student[-trn_idx, ]
```

### Linear regression

#### Diagnostics

And provide a set function for diagnostics of the model:

```{r}
accuracy = function(model) {
  mean(round(predict(model, newdata = student_tst)) == student_tst$G3)
}

loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

influence = function(model, alpha = 0.01) {
  model_coef = summary(model)$coefficients
  model_coef[model_coef[,"Pr(>|t|)"] < alpha, "Pr(>|t|)"]
}
```

Let's find the accuracy baseline, which we will try to beat:

```{r}
baseline_mod = lm(G3 ~ 1, data = student_trn)
coef(baseline_mod)[[1]]
```

Our baseline model would always predict ``r coef(baseline_mod)[[1]]``. 

```{r}
accuracy(baseline_mod)
```

It would get an accuracy score of ``r accuracy(baseline_mod)``, which we wil try to beat.

#### Initial model evaluation {#initialModelEvalLinear}

Now we'll build full additive model using and compare P-values to $\alpha=0.01$:

```{r, cache=TRUE}
full_add_mod = lm(G3 ~ ., data = student_trn)
influence(full_add_mod)
```

We're finding `G2` and `G1` as being very influential for the outcome of `G3`. This is expected, but we'd like to understand influence of other factors that the exams themselves, thus we'll remove both and try another model:

```{r, cache=TRUE}
large_add_mod = lm(G3 ~ . - G2 - G1, data = student_trn)
influence(large_add_mod)
```

We're discovering `school`, `studytime`, `failures`, `higher` and `romantic` are being the most influential predictors, rejecting null hypothesis for any reasonable $\alpha$ level. Let's build a model out of those predictors:

```{r, cache=TRUE}
small_add_mod = lm(G3 ~ school + studytime + failures + higher + romantic, data = student_trn)
coef(small_add_mod)
```

And compare it to the full additive model that has `G2` and `G1` removed:

```{r}
anova(large_add_mod, small_add_mod)$`Pr(>F)`[2]
```

We reject null hypothesis at $\alpha = 0.5$. The more complex model performs better. 

But let's also check how the models perform on unseen data:

```{r}
perf = data.frame(c(accuracy(full_add_mod), accuracy(large_add_mod), accuracy(small_add_mod)),
                  c(loocv_rmse(full_add_mod), loocv_rmse(large_add_mod), loocv_rmse(small_add_mod)))
colnames(perf) = c("Accuracy on test set", "LOOCV RMSE")
row.names(perf) = c("Full additive model (incl. G1 and G2)", "Large additive model (excl. G1 and G2)", "Small additive model")
perf
```

Also here the large additive model (excluding `G1` and `G2`) performs better than the small additive model. The model which includes `G1` and `G2` performs the best (as expected), so past performances are the most important predictor for the final term performance.

All models are above the accuracy baseline of ``r accuracy(baseline_mod)``. 

We will continue our search based on the large additive model and based on the full additive model.

Let's start searching for a better model using `AIC` based on the large additive model:

```{r, cache=TRUE}
scope = formula(lm(G3 ~ (. - G1 - G2) ^ 3, data = student_trn))
int_mod_large_AIC = step(small_add_mod, scope = scope, direction = "forward", trace = 0)
```

```{r}
accuracy(int_mod_large_AIC)
loocv_rmse(int_mod_large_AIC)
```

Using `AIC` we get a model which does not well perform on unseen data (ie overfitting), we will therefore switch to `BIC`.

```{r, cache=TRUE}
n = nrow(student_trn)
scope = formula(lm(G3 ~ (. - G1 - G2) ^ 3, data = student_trn))
int_mod_large_BIC = step(small_add_mod, scope = scope, direction = "forward", trace = 0, k = log(n))
```

```{r}
accuracy(int_mod_large_BIC)
loocv_rmse(int_mod_large_BIC)
```

We were able to improve our accuracy from ``r accuracy(large_add_mod)`` to ``r accuracy(int_mod_large_BIC)``.

Based on the improved model, we will also try to do a polynomial transformation:

```{r, cache=TRUE}
int_pol_mod_large = lm(G3 ~ school + I(studytime ^ 2) + I(failures ^ 2) + higher + romantic + I(Medu ^ 2) + sex + schoolsup, data = student_trn)
```

```{r}
accuracy(int_pol_mod_large)
loocv_rmse(int_pol_mod_large)
```

The polynomial transformation did not deliver an improvement on unseen data for the large model (excl. `G1` and `G2`).

Now let's do the same thing with the full model (including `G1` and `G2`). We will right aways start with `BIC` so to avoid overfitting (which we have seen before when using `AIC`):

```{r, cache=TRUE}
n = nrow(student_trn)
scope = formula(lm(G3 ~ (.) ^ 3, data = student_trn))
int_mod_full_BIC = step(small_add_mod, scope = scope, direction = "forward", trace = 0, k = log(n))
```

```{r}
accuracy(int_mod_full_BIC)
loocv_rmse(int_mod_full_BIC)
```

We were able to improve our accuracy from ``r accuracy(full_add_mod)`` to ``r accuracy(int_mod_full_BIC)``.

Based on the improved model, we will also try to do a polynomial transformation:

```{r, cache=TRUE}
int_pol_mod_full = lm(G3 ~ school + I(studytime ^ 2) + I(failures ^ 2) + I(G2 ^ 2) + I(G1 ^ 2) + higher + romantic + higher:romantic + G2:G1, data = student_trn)
```

```{r}
accuracy(int_pol_mod_full)
loocv_rmse(int_pol_mod_full)
```

This could further increase our accuracy from ``r accuracy(full_add_mod)`` to ``r accuracy(int_pol_mod_full)``.

#### Regression diagnostics

Based on the best initial models, we will perform regression diagnostics to try to further improve performance.

We will start with the full interaction polynomial model.

At first let's see whether we have influential observations:

```{r}
influential_obs_idx = cooks.distance(int_pol_mod_full) > 4 / length(cooks.distance(int_pol_mod_full))
sum(influential_obs_idx)
```

We will remove these ``r sum(influential_obs_idx)`` observations.

```{r}
student_trn_cleaned = student_trn[!influential_obs_idx, ]
```

```{r, cache=TRUE}
int_pol_mod_full_cleaned = lm(G3 ~ school + I(studytime ^ 2) + I(failures ^ 2) + I(G2 ^ 2) + I(G1 ^ 2) + higher + romantic + higher:romantic + G2:G1, data = student_trn_cleaned)
```

```{r}
accuracy(int_pol_mod_full_cleaned)
loocv_rmse(int_pol_mod_full_cleaned)
```

We were not able to improve the performance.

Let's try the same thing on our large model (excl. `G1` and `G2`).

```{r}
influential_obs_idx = cooks.distance(int_mod_large_BIC) > 4 / length(cooks.distance(int_mod_large_BIC))
sum(influential_obs_idx)
```

We will remove these ``r sum(influential_obs_idx)`` observations.

```{r}
student_trn_cleaned = student_trn[!influential_obs_idx, ]
```

```{r}
int_mod_large_BIC_cleaned = lm(formula = G3 ~ school + studytime + failures + higher + romantic + 
    Medu + sex + schoolsup, data = student_trn_cleaned)
```

```{r}
accuracy(int_mod_large_BIC_cleaned)
loocv_rmse(int_mod_large_BIC_cleaned)
```

For this model, the removal of unusual observations did also not lead to a performance increase.

Let's also take a look at fitted-vs-residuals and QQ-plot. At first we will define a `diagnostics` function, which will (1) plot fitted-vs-residuals plot, (2) plot qq-plot, (3) calculate sw-test, (4) calcualted bp-test. (function will not be knitted to html)

```{r message=FALSE}
library(lmtest)

diagnostics = function(model, pcol = "grey", lcol = "dodgerblue", alpha = 0.05, plotit = TRUE, testit = TRUE) {
  if (plotit == TRUE) {
    par(mfrow = c(1, 2))
    
    # Fitted vs residuals plot
    plot(fitted(model), resid(model), 
         col = pcol, 
         pch = 20,
         xlab = "Fitted", 
         ylab = "Residuals", 
         main = "Fitted vs residuals plot")
    abline(h = 0, 
           col = lcol, 
           lwd = 2)
    
    # QQ-plot
    qqnorm(resid(model), 
           main = "Normal Q-Q Plot", 
           col = pcol)
    qqline(resid(model), 
           col = lcol, 
           lwd = 2)
  }
  if (testit == TRUE) {
    p_sw = shapiro.test(resid(model))$p.value
    if (p_sw < alpha) {
      decision_sw = "Reject | Data not sampled from normal"
    } else {
      decision_sw = "Fail to Reject | Data sampled from normal"
    }
    p_bp = bptest(model)$p.value
    if (p_bp < alpha) {
      decision_bp = "Reject | Question equal variance"
    } else {
      decision_bp = "Fail to Reject | Likely equal variance"
    }
    list("p_val_sw" = p_sw, "decision_sw" = decision_sw, "p_val_bp" = p_bp, "decision_bp" = decision_bp)
  }
}
```

Let's analyse our so far best model:

```{r}
diagnostics(int_pol_mod_full)
```

And also the cleaned version of our so far best model:

```{r}
diagnostics(int_pol_mod_full_cleaned)
```

While the plots for our so far best model do not look so good, most of the issues could be resolved by removing unusual observations. However, since the model with the unusual observations removed performs significantly worse on unseen data, we will stick to the initial version (without unusual observations removed).

### Logistic regression

I think our main difficulty is in the fact that the score is a number of 0..19 which is quite hard to pinpoint exactly having limited number of samples.

We will redefine our problem in terms of logistic regression. Taking `10` as a `PASS` threshold and build a model for that:

```{r} 
student_trn$outcome = ifelse(student_trn$G3 > 10, 1, 0)
student_tst$outcome = ifelse(student_tst$G3 > 10, 1, 0)
```

```{r}
bern_full = glm(outcome ~ . - G3, data = student_trn, family = "binomial")

bern_accuracy = function(model) {
  mean(ifelse(predict(model, student_tst) > 0, 1, 0) == student_tst$outcome)
}

bern_accuracy(bern_full)
loocv_rmse(bern_full)
```

90%

*The methods section should contain the bulk of your “work.” This section will contain the bulk of the R code that is used to generate the results. Your R code is not expected to be perfect idiomatic R, but it is expected to be understood by a reader without too much effort. Use RMarkdown and code comments to your advantage to explain your code if needed.*

*This section should contain any information about data preparation that is performed to the original data before modelling. Then you will apply methods seen in class, which may include some of the following but are not limited to:*

*Multiple linear regression*
*Dummy variables*
*Interaction*
*Residual diagnostics*
*Outlier diagnostics*
*Transformations*
*Polynomial regression*
*Model selection*
*Your task is not to use as many methods as possible. Your task is to use appropriate methods to find a good model that can correctly answer a question about the dataset, and then to communicate your result effectively.*

# Results

## Linear regression

The following table shows the $LOOCV-RMSE$ and **accuracy** on test data of the best initial models we built (see [Initial Model Evaluation](#initialModelEvalLinear)) using linear regression:

```{r, echo = FALSE}
results_df = rbind(
  "Full (incl. G1 and G2) polynomial, interaction model" = c(accuracy(int_pol_mod_full), loocv_rmse(int_pol_mod_full)),
  "Large (excl. G1 and G2) additive model" = c(accuracy(int_mod_large_BIC), loocv_rmse(int_mod_large_BIC)),
  "Small additive model" = c(accuracy(small_add_mod), loocv_rmse(small_add_mod)),
  "Baseline model" = c(accuracy(baseline_mod), loocv_rmse(baseline_mod))
)
colnames(results_df) = c("Accuracy on test data", "LOOCV-RMSE")


kable(results_df,
      format = 'markdown',
      digits = 3
      )
```

We will continue with the two best performing models from our two perspectives `Full (incl. G1 and G2)` and `Large (excl. G1 and G2)` (see [discussion chapter](#discussion_chapter) for explanation of this distinction).

Let's plot the actual vs. predicted G3 performance for our two best models. 

```{r echo = FALSE}
plot(x = round(predict(int_pol_mod_full, newdata = student_tst)), y = student_tst$G3,
     pch  = 20,
     cex  = 2,
     col  = "darkblue",
     xlim = c(0, 20),
     ylim = c(0, 20),
     main = "Full interaction, polynomial model: predicted G3 vs. actual G3",
     xlab = "Rounded predicted G3 performance",
     ylab = "Actual G3 performance")
lines(x = c(0, 20), y = c(0, 20),
      lwd = 2,
      col = "orange")
```

```{r echo = FALSE}
plot(x = round(predict(int_mod_large_BIC, newdata = student_tst)), y = student_tst$G3,
     pch  = 20,
     cex  = 2,
     col  = "darkblue",
     xlim = c(0, 20),
     ylim = c(0, 20),
     main = "Large additive modell: predicted G3 vs. actual G3",
     xlab = "Rounded predicted G3 performance",
     ylab = "Actual G3 performance")
lines(x = c(0, 20), y = c(0, 20),
      lwd = 2,
      col = "orange")
```

The plots show us:

1. For students with a performance of `0` in `G3`, both models perform the worst (although the full model is a bit better). So if a students completly fails `G3`, this is probably due to special circumstances. 
2. The trend predicted by both models is correct. The large model not taking `G1` and `G2` into account, is not as precise as the full model but does still cover the trend correctly.

This means: 

* Both models can be used to explain how social and demographic features could impact the trend of the students performance. 
* Special circumstances leading to `0` points can not be explained by the data. 
* `G1` and `G2` are needed to more or lesss precisely estimate the grade (+/- ~3 points). Without them, the trend is still present, but the precision goes down (+/- ~6).


## Logistic regression

*The results section should contain numerical or graphical summaries of your results. You should report a final model you have chosen. There is not necessarily one, singular correct model, but certainly some methods and models are better than others in certain situations. You may use any methods we studied this semester to complete this task, and provide evidence that your final choice of model is a good one.*

# Discussion {#discussion_chapter}

We are differentiating between `Full (incl. G1 and G2)` and `Large (excl. G1 and G2)` in the results. The reason for that is, that `G1` and `G2` have a high multicollinearity with the response `G3`. Also intuitively it makes sense that the past performance of a student is highly correlated with his/her future performance. Since our goal is to explain what social and demographic features impact future performance, we want to consider a model which therefore excludes `G1` and `G2` so that the other predictors can easier be used for interpretation.

The predicted vs. actual plots show us that:

* Both models can be used to explain how social and demographic features could impact the trend of the students performance. 
* Special circumstances leading to `0` points can not be explained by the data. 
* `G1` and `G2` are needed to more or lesss precisely estimate the grade (+/- ~3 points). Without them, the trend is still present, but the precision goes down (+/- ~6).

*The discussion section should contain discussion of your results and should frame your results in the context of the data. How is your final model useful?*

# Appendix

*The appendix section should contain code and analysis that is used, but that may clutter the report or is not directly related to the choice of model.*
